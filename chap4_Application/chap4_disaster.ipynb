{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このページは以下のリンクより， google colaboratoryから動作させることができる．\n",
    "- [Open with Colab](https://colab.research.google.com/github/crotsu/Bousai_AI/blob/master/chap4_Application/chap4_disaster.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# 学習\n",
    "#\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Dense\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "\n",
    "# 変数の宣言\n",
    "classes = 2 # クラスの数：災害 or 非災害\n",
    "data_size = 200 * 200 * 3 # 縦200×横200×3原色\n",
    "\n",
    "# データを学習しモデルを評価する\n",
    "\n",
    "###### 注意 ##############################\n",
    "# 別途ダウンロードしたdisaster.npzファイルをアップロードする\n",
    "########################################\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "# データの読み込み\n",
    "data = np.load(\"disaster.npz\")\n",
    "x = data[\"X\"] # 画像データ\n",
    "y = data[\"y\"] # ラベルデータ\n",
    "\n",
    "# データを2次元に変形する\n",
    "x = np.reshape(x, (-1, data_size))\n",
    "\n",
    "# 訓練データとテストデータに分割\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "# モデルを訓練し評価\n",
    "\n",
    "# モデルの構築\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, input_dim=(data_size)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(units=classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "#データを学習\n",
    "model.fit(x_train, y_train, epochs=60)\n",
    "\n",
    "# モデルを評価する\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('loss=', score[0])\n",
    "print('accuracy=', score[1])\n",
    "\n",
    "\n",
    "# 別途ダウンロードしたtest.npzファイルをアップロードする\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "# テストデータ\n",
    "data = np.load(\"test.npz\")\n",
    "\n",
    "x = data[\"X\"] # 画像データ\n",
    "y = data[\"y\"] # ラベルデータ\n",
    "x = np.reshape(x, (-1, data_size))\n",
    "print(model.predict(x))\n",
    "print(model.predict_classes(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# 判定\n",
    "#\n",
    "\n",
    "# 別途ダウンロードしたtest.npzファイルをアップロードする\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "# テストデータ\n",
    "data = np.load(\"test.npz\")\n",
    "\n",
    "x = data[\"X\"] # 画像データ\n",
    "y = data[\"y\"] # ラベルデータ\n",
    "x = np.reshape(x, (-1, data_size))\n",
    "print(model.predict(x))\n",
    "print(model.predict_classes(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
